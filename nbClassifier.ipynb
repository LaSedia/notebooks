{
 "metadata": {
  "name": "",
  "signature": "sha256:21b22f2162b37d5017d287d7b8e0be3d82ea4c9d9ba3e574a8f0283ccb43fe55"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "DOCUMENT FILTERING"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O c\u00f3digo deste exemplo se baseia no exemplo de **_Segaran_ 2007**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ao classificar documentos -- precisaremos de algumas coisas:\n",
      "\n",
      "i) _features_ i.e. qualquer coisa que voc\u00ea pode determinar como *presente* ou *ausente* no documento, ou que voc\u00ea possa *contar* nos documentos;\n",
      "<br>ii) _classes_; se n\u00e3o estivermos fazendo _Topic Modeling_ as classes que queremos usar, muitas vezes, s\u00e3o dadas (e.g. fraudulento vs. normal, CV desej\u00e1vel vs. n\u00e3o, \n",
      "<br>iii) bem ...mais documentos. A maioria dos modelos de classifica\u00e7\u00e3o s\u00e3o **supervisionados** (todo mundo sabe a diferen\u00e7a? -- sen\u00e3o estar\u00e1 na pr\u00f3xima aula!)\n",
      "\n",
      "Bem, ao considerar documentos para classifica\u00e7\u00e3o, um bom candidato para _features_ s\u00e3o as palavras do documento. Outros incluem: as entidades nomeadas (named-entities); os meta-dados associados ou ???<br>mas para este exemplo, vamos com as palavras:\n",
      "\n",
      "Criamos uma fun\u00e7\u00e3o em python que extrai as palavras de um documento:\n",
      "\n",
      "OBS.: O c\u00f3digo em si n\u00e3o importa tanto quando os conceitos!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# coding: utf-8\n",
      "import re\n",
      "\n",
      "def getwords(doc):\n",
      "    splitter = re.compile('\\\\W*')\n",
      "    # Split the words by non-alpha characters\n",
      "    words = [s.lower() for s in splitter.split(doc) if len(s) > 2 and len(s) < 20]\n",
      "    \n",
      "    #print words  # usamos isso para checar o split depois\n",
      "    \n",
      "    # retorno o set de palavras \u00daNICAS!\n",
      "    res = dict([(w, 1) for w in words])\n",
      "    # print 'res:',res # veja\n",
      "    \n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Esta fun\u00e7\u00e3o divide um _string_ partindo em cada coisa que n\u00e3o \u00e9 uma letra e convertendo para min\u00fasculo."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "OBS SOBRE A ESCOLHA DE _FEATURES_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A escolha das _features_ \u00e9 muito importante. E dif\u00edcil. Os documentos precisam ter algumas _features_ em comum, mas uma _feature_ que ocorre em **todo** documento \u00e9 in\u00fatil para a classifica\u00e7\u00e3o. \n",
      "\n",
      "Em tese o texto inteiro de cada documento poderia ser uma feature. Mas a\u00ed teriamos um classificador que coloca cada um documento em uma classe separada (a n\u00e3o ser que haja documentos exatamente iguais).Do outro lado do espectro, podemos usar a letras como _features_, mas a\u00ed coo todos os documentos de um _corpus_ em geral tendem a ter o mesmo alfabeto, elas n\u00e3o seriam uma forma efetiva de separar documentos.\n",
      "\n",
      "at\u00e9 **quais** palavras utilizar pode ser problem\u00e1tico, usamos pontua\u00e7\u00e3o ou n\u00e3o? quais as melhores regras para dividir palavras? Usamos o t\u00edtulo (em caso de artigos ou not\u00edcias)? Colocar em min\u00fasculo perde a informa\u00e7\u00e3o de nomes pr\u00f3prios, in\u00edcios de frase, acr\u00f4nimos.\n",
      "\n",
      "Por exemplo -- para um detector de SPAM ...o estilo GRITADO DE DIGITAR \u00c9 CRUCIAL PARA DISTIGUIR MENSAGENS, E O N\u00daMERO DE EXCLAMA\u00c7\u00d5ES TAMB\u00c9M!!!!!\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "VAMOS TREINAR?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Com isso em mente, vamos programar e treinar o nosso classificador. Classificadores supervisionados melhoram \u00e0 medida que v\u00eaem mais e mais documentos (tomando cuidado com _overfitting/overtraining_).**Todo mundo sabe o que \u00e9 overfitting/overtraining?? Sen\u00e3o, veremos na pr\u00f3xima aula!**\n",
      "\n",
      "Vamos escrever uma classe gen\u00e9rica que descreve um classificador:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class classifier:\n",
      "    \"\"\" a generic classifier, for use as an example to set up naive bayes \"\"\"\n",
      "    def __init__(self,  getfeatures,  filename=None):\n",
      "        # contagem de combin\u00e7\u00f5es: feature/categoria\n",
      "        # {'python': {'bad': 0, 'good': 6}, 'the': {'bad': 3, 'good': 3}}\n",
      "        self.fc = {}\n",
      "        \n",
      "        # contagem de documentos em cada cat.\n",
      "        self.cc = {}\n",
      "        \n",
      "        # fn. de extra\u00e7\u00e3o de features (passada como input)\n",
      "        self.getfeatures = getfeatures\n",
      "        \n",
      "        # \n",
      "        self.thresholds = {}\n",
      "        \n",
      "    # #################################################################\n",
      "    # estes s\u00e3o helper methods para que nossa classe permane\u00e7a gen\u00e9rica\n",
      "    # #################################################################\n",
      "    def incf(self,  f,  cat):\n",
      "        \"\"\"Incr. a contagem de feature/cat\"\"\"\n",
      "        self.fc.setdefault(f, {})\n",
      "        self.fc[f].setdefault(cat, 0)\n",
      "        self.fc[f][cat] += 1\n",
      "\n",
      "    def incc(self,  cat):\n",
      "        \"\"\"Incr. a contagem de uma cat\"\"\"\n",
      "        self.cc.setdefault(cat, 0)\n",
      "        self.cc[cat] += 1\n",
      "\n",
      "    def fcount(self,  f,  cat):\n",
      "        \"\"\"num. de vezes uma feature aparece em uma cat\"\"\"\n",
      "        if f in self.fc and cat in self.fc[f]:\n",
      "            return float(self.fc[f][cat])\n",
      "        return 0.0\n",
      "\n",
      "    def catcount(self,  cat):\n",
      "        \"\"\"num. de itens em uma cat.\"\"\"\n",
      "        if cat in self.cc:\n",
      "            return float(self.cc[cat])\n",
      "        return 0\n",
      "\n",
      "    def totalcount(self):\n",
      "        \"\"\"num. total de itens\"\"\"\n",
      "        return sum(self.cc.values())\n",
      "    \n",
      "    def categories(self):\n",
      "        \"\"\"lista de categorias\"\"\"\n",
      "        return self.cc.keys()\n",
      "    # #################################################################     \n",
      "    def train(self, item, cat):\n",
      "        \"\"\"pego um documento classificado, parto em features e adiciono as \n",
      "            contagens pertinentes para este documento\"\"\"\n",
      "        features = self.getfeatures(item)\n",
      "        # incr. a contagem para cada feature na cat.\n",
      "        for f in features:\n",
      "            self.incf(f, cat)\n",
      "        # incr. a contagem na cat.\n",
      "        self.incc(cat)\n",
      "    # #################################################################            \n",
      "    def fprob(self, f, cat):\n",
      "        \"\"\"probabilidade de uma feature >F< ocorrer na categoria >C<:\n",
      "            num. de vezes F aparece em C sobre o num de itens em C\n",
      "        \"\"\"\n",
      "        if self.catcount(cat) == 0: return 0  # se vazio, retorna 0\n",
      "        return self.fcount(f, cat)/self.catcount(cat)\n",
      "    \n",
      "    def weightedprob(self, f, cat, prf, weight=1.0, ap=0.5):\n",
      "        \"\"\"probabilidade ponderada\n",
      "            weight \u00e9 o peso (em qtd de palavras) que a prob assumida tem\n",
      "            ap \u00e9 a probabilidade assumida (assumed probability - ap)\n",
      "        \"\"\"\n",
      "        # calcular a probabilidade basica\n",
      "        basicprob = prf(f, cat)\n",
      "    \n",
      "        # contar o numero de vezes que a feature aparece em TODAS as categorias\n",
      "        totals = sum([self.fcount(f, c) for c in self.categories()])\n",
      "        \n",
      "        # calculae a probabilidade ponderada\n",
      "        bp = ((weight * ap) + (totals * basicprob)) / (weight + totals)\n",
      "        #  = (   1  *  0.5) + (soma   *   prob   )  / (  1    + soma  )\n",
      "        \n",
      "        return bp\n",
      "    # ################################################################# \n",
      "    \n",
      "    def setthreshold(self, cat, t):\n",
      "        self.thresholds[cat] = t\n",
      "    \n",
      "    def getthreshold(self, cat):\n",
      "        if cat not in self.thresholds: return 1.0\n",
      "        return self.thresholds[cat]\n",
      "    \n",
      "    def classify(self, item, default=None):\n",
      "        probs = {}\n",
      "        # Encontre a classe com a maior probabilidade\n",
      "        max = 0.0\n",
      "        for cat in self.categories():\n",
      "            probs[cat] = self.prob(item, cat)\n",
      "            if probs[cat] > max:\n",
      "                max = probs[cat]\n",
      "                best = cat\n",
      "        # garante que a probabilidade excede threshold*next best\n",
      "        for cat in probs:\n",
      "            if cat == best: continue\n",
      "            if probs[cat] * self.getthreshold(best) > probs[best]: return default\n",
      "        return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos checar os helpers?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl=classifier(getwords)\n",
      "cl.train('the quick brown quick fox jumps over the lazy dog','good')\n",
      "cl.train('make quick money in the online casino','bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.fcount('the','good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.fcount('quick','bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Agora podemos criar uma fun\u00e7\u00e3o place-holder para um _corpus_ de e-mails; e vamos tentar achar SPAM."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sampletrain(cl):\n",
      "    cl.train('Nobody owns the water.', 'good')\n",
      "    cl.train('the quick rabbit jumps fences', 'good')\n",
      "    cl.train('buy pharmaceuticals now', 'bad')\n",
      "    cl.train('make quick money at the online casino', 'bad')\n",
      "    cl.train('the quick brown fox jumps', 'good')\n",
      "    # cl.train('Mike stores his money in bonds','good')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Adicionamos \u00e0 nossa classe fun\u00e7\u00f5es de contagem, agora vamos extrair probabilidades: A fun\u00e7\u00e3o <code>fprob</code> faz exatamente isso, veja l\u00e1.\n",
      "\n",
      "Zeramos o classificador e treinamos no _corpus_ anotado (j\u00e1 classificado)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl=classifier(getwords)\n",
      "sampletrain(cl)\n",
      "cl.fprob('quick','good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "0.6666666666666666"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Isso se chama _probabilidade condicional_: Pr(A | B). \n",
      "\n",
      "Neste exemplo temos a probabilidade Pr(palavra | classe), isto \u00e9, para uma dada classifica\u00e7\u00e3o, calculamos a probabilidade de uma dada palavra aparecer."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "UM BOM CHUTE ..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<code>fprob</code> tem um leve problema, que \u00e9 usar a informa\u00e7\u00e3o que foi vista at\u00e9 um dado momento torna o modelo **sens\u00edvel** durante o in\u00edcio do treino e a palavras que ocorrem **raramente**. 'Money' aparece somente uma vez e \u00e9 classificada como ruim pois aparece em um an\u00fancio de casino, mas 'money' pode ser (e provavelmente \u00e9) uma palavra neutra em um corpo de e-mails gen\u00e9rico.\n",
      "\n",
      "Com isso, a probabilidade de 'money' aparecer em 'good' agora \u00e9 **zero**. Seria muito mais realistico se o valor gradualmente se aproximasse de zero \u00e0 medida que mais e mais documentos fossem vistos.\n",
      "\n",
      "Assim, vamos partir de uma probabilidade assumida (0.5, por exemplo) e um peso para esta probabilidade: um peso de 1 significa que ela vale **uma palavra**, assim a nossa probabilidade com pesos (<code>weighedprob</code> l\u00e1 em cima) ser\u00e1 uma m\u00e9dia ponderada entre a palavra e e a probabilidade assumida).\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "NAIVE BAYES"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Uma vez que temo as probabilidades de cada categoria conter uma certa palavra, podemos combinar as probabilidades de palavras individuais para ter a probabilidade de um documento pertencer a uma dad classe.\n",
      "\n",
      "Este m\u00e9todo se chama 'na\u00efve' (ing\u00eanuo) pois parte da premissa que as probabilidades sendo combinadas s\u00e3o **independentes** (por isso multiplicamos) \u2013 isto \u00e9 \u2013 assumimos que a probabilidade de uma palavra de um documento ocorrer em uma categoria \u00e9 **independente** de todas as outras palavras serem um n\u00e3o daquela categoria\n",
      "\n",
      "Isto n\u00e3o \u00e9 verdade, N\u00e9?\n",
      "\n",
      "A palavra 'casino' deve ocorrer junto com 'ganhar' muito mais que com 'alum\u00ednio' ou 'feijoada' (pelo menos eu espero).\n",
      "\n",
      "Para um classificador Naive Bayes, precisamos da probabilidade de um documento inteiro ser dado uma classifica\u00e7\u00e3o. Por assumir independ\u00eancia, podemos somente multiplicar as probabilidades individuais das palavras para obter a do documento. Veja <code>docprob</code> abaixo.\n",
      "\n",
      "\n",
      "Agora sabemos calcular Pr(Documento | Classe), mas isso n\u00e3o serve de muito.\n",
      "\n",
      "Para classificar documentos precisamos de Pr(Class | Documento), ou seja, dado o documento qual a probabilidade de ele pertencer a uma classe espec\u00edfica."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Teorema de Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Entra o Teorema de Bayes:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pr(A | B) = Pr(B | A) x Pr(A) / Pr(B)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ou seja: Pr(Classe | Documento) = Pr(Documento | Classe) x Pr(Classe) / Pr(Documento)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assim, Pr(Classe) \u00e9 a probabilidade de um documento aleat\u00f3rio ser\u00e1 deste classe, ent\u00e3o \u00e9 s\u00f3 o n\u00famero de documentos na classe divido pel numero total de documentos.\n",
      "\n",
      "Pr(Documento) \u00e9 desnecess\u00e1rio pois os resultados n\u00e3o ser\u00e3o usados em uma probabilidade, e sim apenas comparativamente entre (e todos ter\u00e3o o mesmo denominador), ent\u00e3o podemos ignor\u00e1-lo!\n",
      "\n",
      "The prob method calculates the probability of the category, and returns the product of Pr(Document | Category) and Pr(Category). Add this method to the naivebayes class:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class naivebayes(classifier):\n",
      "    \n",
      "    def docprob(self,  item,  cat):\n",
      "        \"\"\"pega a probabilidade multiplicada de cada feature (palavra) do documento\"\"\"\n",
      "        # pegar as feature\n",
      "        features = self.getfeatures(item)\n",
      "        # Multiply the probabilities of all the features together\n",
      "        p = 1\n",
      "        for f in features:\n",
      "            p *= self.weightedprob(f,   cat,  self.fprob)\n",
      "        return p\n",
      "    \n",
      "    def prob(self, item, cat):\n",
      "        \n",
      "        # calculando Pr(Classe)\n",
      "        catprob = self.catcount(cat) / self.totalcount()\n",
      "        \n",
      "        # calculando Pr(Doc | Classe)\n",
      "        docprob = self.docprob(item, cat)\n",
      "        \n",
      "        # retornando Pr( Classe | Doc) = Pr(Doc | Classe) * Pr(Classe)\n",
      "        return docprob*catprob\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Escolhendo uma categoria"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O ultimo passo \u00e9 escolher uma classe para o documento. A forma mais simples seria calcular as probabilidades de cada classe e escolher a maior.\n",
      "\n",
      "H\u00e1 algum problema com isso?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "\n",
      "    cl = classifier(getwords)\n",
      "    sampletrain(cl)\n",
      "    print 'fprob for \"money\" being good', cl.fprob('money', 'good')\n",
      "    print 'fprob for \"money\" being bad', cl.fprob('money', 'bad')\n",
      "\n",
      "    print '\\nweightedprob for \"money\" being good', cl.weightedprob('money', 'good', cl.fprob)\n",
      "    print 'weightedprob for \"money\" being bad', cl.weightedprob('money', 'bad', cl.fprob)\n",
      "    \n",
      "    s = \"money, that's what I want\"\n",
      "    print '\\nretraining on new text:\\t\\t','\"'+s+'\"\\n'\n",
      "    cl.train(s, \"bad\")\n",
      "    \n",
      "    print 'weightedprob for \"money\" being good', cl.weightedprob('money', 'good', cl.fprob)\n",
      "    print 'weightedprob for \"money\" being bad', cl.weightedprob('money', 'bad', cl.fprob)\n",
      "\n",
      "    nbClassifier = naivebayes(getwords)\n",
      "    sampletrain(nbClassifier)\n",
      "    \n",
      "    print \"\\nis 'quick' good?\", nbClassifier.prob('quick', 'good')\n",
      "    print \"is 'quick'  bad?\",nbClassifier.prob('quick', 'bad')\n",
      "    print \"it is classified as:\",nbClassifier.classify('quick', default='unknown')\n",
      "    \n",
      "    s2 = \"Kobe Bryant is like a quick rabbit with the basketball\"\n",
      "    s3 = \"My daughter wants a quick rabbit for her birthday\"\n",
      "    print '\\nretrainting on two new texts...'\n",
      "    print '\\t\\t\"'+s2+'\"'\n",
      "    print '\\t\\t\"'+s3+'\"' \n",
      "    nbClassifier.train(s2, \"bad\")\n",
      "    nbClassifier.train(s3, \"bad\")\n",
      "    \n",
      "    print \"\\nis 'quick' good?\", nbClassifier.prob('quick', 'good')\n",
      "    print \"is 'quick' bad?\",nbClassifier.prob('quick', 'bad')\n",
      "    print 'now it is:',nbClassifier.classify('quick', default='unknown')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fprob for \"money\" being good 0.0\n",
        "fprob for \"money\" being bad 0.5\n",
        "\n",
        "weightedprob for \"money\" being good 0.25\n",
        "weightedprob for \"money\" being bad 0.5\n",
        "\n",
        "retraining on new text:\t\t\"money, that's what I want\"\n",
        "\n",
        "weightedprob for \"money\" being good 0.166666666667\n",
        "weightedprob for \"money\" being bad 0.611111111111\n",
        "\n",
        "is 'quick' good? 0.375\n",
        "is 'quick'  bad? 0.2\n",
        "it is classified as: good\n",
        "\n",
        "retrainting on two new texts...\n",
        "\t\t\"Kobe Bryant is like a quick rabbit with the basketball\"\n",
        "\t\t\"My daughter wants a quick rabbit for her birthday\"\n",
        "\n",
        "is 'quick' good? 0.27380952381\n",
        "is 'quick' bad? 0.404761904762\n",
        "now it is: bad\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}