{
 "metadata": {
  "name": "",
  "signature": "sha256:377109f8d7438e314c6c1f6aa980b19276c59cceb4b97ca2c5c22ac6f5f56da2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<center>DOCUMENT FILTERING</center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O c\u00f3digo deste exemplo se baseia no exemplo de **_Segaran_ 2007**: \"Programming Collective Intelligence\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ao classificar documentos -- precisaremos de algumas coisas:\n",
      "\n",
      "i) _features_ i.e. qualquer coisa que voc\u00ea pode determinar como *presente* ou *ausente* no documento, ou que voc\u00ea possa *contar* nos documentos;\n",
      "<br>ii) _classes_; se n\u00e3o estivermos fazendo _Topic Modeling_ as classes que queremos usar, muitas vezes, s\u00e3o dadas (e.g. fraudulento vs. normal, CV desej\u00e1vel vs. n\u00e3o, \n",
      "<br>iii) bem ...mais documentos. A maioria dos modelos de classifica\u00e7\u00e3o s\u00e3o **supervisionados** (todo mundo sabe a diferen\u00e7a? -- sen\u00e3o estar\u00e1 na pr\u00f3xima aula!)\n",
      "\n",
      "Bem, ao considerar documentos para classifica\u00e7\u00e3o, um bom candidato para _features_ s\u00e3o as palavras do documento. Outros incluem: as entidades nomeadas (named-entities); os meta-dados associados ou ???<br>mas para este exemplo, vamos com as palavras:\n",
      "\n",
      "Criamos uma fun\u00e7\u00e3o em python que extrai as palavras de um documento:\n",
      "\n",
      "<h4>OBS.: O c\u00f3digo em si n\u00e3o importa tanto quando os conceitos!</h4>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# coding: utf-8\n",
      "import re\n",
      "\n",
      "def getwords(doc):\n",
      "    splitter = re.compile('\\\\W*')\n",
      "    # Split the words by non-alpha characters\n",
      "    words = [s.lower() for s in splitter.split(doc) if len(s) > 2 and len(s) < 20]\n",
      "    \n",
      "    #print words  # usamos isso para checar o split depois\n",
      "    \n",
      "    # retorno o set de palavras \u00daNICAS!\n",
      "    res = dict([(w, 1) for w in words])\n",
      "    # print 'res:',res # veja\n",
      "    \n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Esta fun\u00e7\u00e3o divide um _string_ partindo em cada coisa que n\u00e3o \u00e9 uma letra e convertendo para min\u00fasculo."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "OBS SOBRE A ESCOLHA DE _FEATURES_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A escolha das _features_ \u00e9 muito importante. E dif\u00edcil. Os documentos precisam ter algumas _features_ em comum, mas uma _feature_ que ocorre em **todo** documento \u00e9 in\u00fatil para a classifica\u00e7\u00e3o. \n",
      "\n",
      "Em tese o texto inteiro de cada documento poderia ser uma feature. Mas a\u00ed teriamos um classificador que coloca cada um documento em uma classe separada (a n\u00e3o ser que haja documentos exatamente iguais). Do outro lado do espectro, podemos usar as letras como _features_, mas a\u00ed como todos os documentos de um _corpus_ em geral tendem a ter o mesmo alfabeto, elas n\u00e3o seriam uma forma efetiva de separar documentos.\n",
      "\n",
      "at\u00e9 **quais** palavras utilizar pode ser problem\u00e1tico, usamos pontua\u00e7\u00e3o ou n\u00e3o? quais as melhores regras para dividir palavras? Usamos o t\u00edtulo (em caso de artigos ou not\u00edcias)? Colocar em min\u00fasculo perde a informa\u00e7\u00e3o de nomes pr\u00f3prios, in\u00edcios de frase, acr\u00f4nimos.\n",
      "\n",
      "Por exemplo -- para um detector de SPAM ...o estilo 'GRITADO' DE DIGITAR \u00c9 CRUCIAL PARA DISTIGUIR MENSAGENS, E O N\u00daMERO DE EXCLAMA\u00c7\u00d5ES TAMB\u00c9M!!!!!\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "VAMOS TREINAR?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Com isso em mente, vamos programar e treinar o nosso classificador. Classificadores supervisionados melhoram \u00e0 medida que v\u00eaem mais e mais documentos (tomando cuidado com _overfitting/overtraining_).\n",
      "\n",
      "<h4>Todo mundo sabe o que \u00e9 overfitting/overtraining?? Sen\u00e3o, veremos na pr\u00f3xima aula!</h4>\n",
      "\n",
      "Vamos escrever uma classe gen\u00e9rica que descreve um classificador:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class classifier:\n",
      "    \"\"\" um classificador gen\u00e9rico que serve para trinar um Na\u00efve Bayes \"\"\"\n",
      "    def __init__(self,  getfeatures,  filename=None):\n",
      "        # contagem de combina\u00e7\u00f5es: feature/categoria\n",
      "        # ex: {'python': {'bad': 0, 'good': 6}, 'the': {'bad': 3, 'good': 3}}\n",
      "        self.featCatCombinations = {}\n",
      "        \n",
      "        # contagem de documentos em cada cat.\n",
      "        # ex: {'good': 385, 'bad':266}\n",
      "        self.docCountPerCat = {}\n",
      "        \n",
      "        # fn. de extra\u00e7\u00e3o de features (recebida como input)\n",
      "        # no nosso caso \u00e9 a getWords\n",
      "        self.getfeatures = getfeatures\n",
      "        \n",
      "        # \n",
      "        self.thresholds = {}\n",
      "        \n",
      "    # #################################################################\n",
      "    # estes s\u00e3o helper methods para que nossa classe permane\u00e7a gen\u00e9rica\n",
      "    # #################################################################\n",
      "    def incrFeatCount(self,  f,  cat):\n",
      "        \"\"\"Incrementa a contagem da feature f na categoria cat\"\"\"\n",
      "        self.featCatCombinations.setdefault(f, {})\n",
      "        self.featCatCombinations[f].setdefault(cat, 0)\n",
      "        self.featCatCombinations[f][cat] += 1\n",
      "\n",
      "    def incrCatCount(self,  cat):\n",
      "        \"\"\"Incr. a contagem de uma cat\"\"\"\n",
      "        self.docCountPerCat.setdefault(cat, 0)\n",
      "        self.docCountPerCat[cat] += 1\n",
      "\n",
      "    def fcount(self,  f,  cat):\n",
      "        \"\"\"num. de vezes uma feature aparece em uma cat\"\"\"\n",
      "        if f in self.featCatCombinations and cat in self.featCatCombinations[f]:\n",
      "            return float(self.featCatCombinations[f][cat])\n",
      "        return 0.0\n",
      "\n",
      "    def catcount(self,  cat):\n",
      "        \"\"\"num. de itens em uma cat.\"\"\"\n",
      "        if cat in self.docCountPerCat:\n",
      "            return float(self.docCountPerCat[cat])\n",
      "        return 0\n",
      "\n",
      "    def totalcount(self):\n",
      "        \"\"\"num. total de itens\"\"\"\n",
      "        return sum(self.docCountPerCat.values())\n",
      "    \n",
      "    def categories(self):\n",
      "        \"\"\"lista de categorias\"\"\"\n",
      "        return self.docCountPerCat.keys()\n",
      "    # #################################################################     \n",
      "    def train(self, item, cat):\n",
      "        \"\"\"pego um documento classificado, parto ele em features e \n",
      "            adiciono as contagens deste doc. ao todo\"\"\"\n",
      "        features = self.getfeatures(item)\n",
      "        # incr. a contagem para cada feature na cat.\n",
      "        for f in features:\n",
      "            self.incrFeatCount(f, cat)\n",
      "        # incr. a contagem na cat.\n",
      "        self.incrCatCount(cat)\n",
      "    # #################################################################            \n",
      "    def fprob(self, f, cat):\n",
      "        \"\"\"probabilidade de uma feature >F< ocorrer na categoria >C<:\n",
      "           i.e: num. de vezes F aparece em C sobre o num de itens em C\n",
      "        \"\"\"\n",
      "        if self.catcount(cat) == 0: return 0  # se vazio, retorna 0\n",
      "        return self.fcount(f, cat)/self.catcount(cat)\n",
      "    \n",
      "    def weightedprob(self, f, cat, prf, weight=1.0, ap=0.5):\n",
      "        \"\"\"probabilidade ponderada (veja abaixo)\n",
      "            weight \u00e9 o peso (em qtd de palavras) que a prob assumida tem\n",
      "            ap \u00e9 a probabilidade assumida (assumed probability - ap)\n",
      "        \"\"\"\n",
      "        # calcular a probabilidade basica\n",
      "        basicprob = prf(f, cat)\n",
      "    \n",
      "        # contar o numero de vezes que a feature aparece em TODAS as categorias\n",
      "        totalOcc = sum([self.fcount(f, c) for c in self.categories()])\n",
      "        \n",
      "        # calcular a probabilidade ponderada\n",
      "        bp = ((weight * ap) + (totalOcc * basicprob)) / (weight + totalOcc)\n",
      "        #  = (   1  *  0.5) + (  soma   * prAssumida) / (  1    +   soma  )\n",
      "        \n",
      "        return bp\n",
      "    # ################################################################# \n",
      "    \n",
      "    def setthreshold(self, cat, t):\n",
      "        self.thresholds[cat] = t\n",
      "    \n",
      "    def getthreshold(self, cat):\n",
      "        if cat not in self.thresholds: return 1.0\n",
      "        return self.thresholds[cat]\n",
      "    \n",
      "    def classify(self, item, default=None):\n",
      "        probs = {}\n",
      "        # Encontre a classe com a maior probabilidade\n",
      "        max = 0.0\n",
      "        for cat in self.categories():\n",
      "            probs[cat] = self.prob(item, cat)\n",
      "            if probs[cat] > max:\n",
      "                max = probs[cat]\n",
      "                best = cat\n",
      "        # garante que a probabilidade excede threshold*next best\n",
      "        for cat in probs:\n",
      "            if cat == best: continue\n",
      "            if probs[cat] * self.getthreshold(best) > probs[best]: return default\n",
      "        return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos checar os helpers?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl=classifier(getwords)\n",
      "cl.train('the quick brown quick fox jumps over the lazy dog','good')\n",
      "cl.train('make quick money in the online casino','bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Veja que a palavra 'the' s\u00f3 aparece uma vez, em um documento bom"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.fcount('the','good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "igualmente, 'quick' s\u00f3 aparece uma vez em um documento classificado como mau:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.fcount('quick','bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Agora podemos criar uma fun\u00e7\u00e3o place-holder para um _corpus_ de e-mails; e vamos tentar achar SPAM."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sampletrain(cl):\n",
      "    cl.train('Nobody owns the water.', 'good')\n",
      "    cl.train('the quick rabbit jumps fences', 'good')\n",
      "    cl.train('buy pharmaceuticals now', 'bad')\n",
      "    cl.train('make quick money at the online casino', 'bad')\n",
      "    cl.train('the quick brown fox jumps', 'good')\n",
      "    # cl.train('Mike stores his money in bonds','good')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Adicionamos \u00e0 nossa classe fun\u00e7\u00f5es de contagem, agora vamos extrair probabilidades: A fun\u00e7\u00e3o <code>fprob</code> faz exatamente isso, veja l\u00e1.\n",
      "\n",
      "Zeramos o classificador e treinamos no _corpus_ anotado (j\u00e1 classificado)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl=classifier(getwords)\n",
      "sampletrain(cl)\n",
      "cl.fprob('quick','good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.6666666666666666"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Isso se chama _probabilidade condicional_: Pr(A | B). \n",
      "\n",
      "Neste exemplo temos a probabilidade Pr(palavra | classe), isto \u00e9, para uma dada classifica\u00e7\u00e3o, calculamos a probabilidade de uma dada palavra aparecer."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "UM BOM CHUTE ..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<code>fprob</code> tem um leve problema, que \u00e9 usar a informa\u00e7\u00e3o que foi vista at\u00e9 um dado momento torna o modelo **sens\u00edvel** durante o in\u00edcio do treino e a palavras que ocorrem **raramente**. 'Money' aparece somente uma vez e \u00e9 classificada como ruim pois aparece em um an\u00fancio de casino, mas 'money' pode ser (e provavelmente \u00e9) uma palavra neutra em um corpo de e-mails gen\u00e9rico.\n",
      "\n",
      "Com isso, a probabilidade de 'money' aparecer em 'good' agora \u00e9 **zero**. Seria muito mais realistico se o valor gradualmente se aproximasse de zero \u00e0 medida que mais e mais documentos fossem vistos.\n",
      "\n",
      "Assim, vamos partir de uma probabilidade assumida (0.5, por exemplo) e um peso para esta probabilidade: um peso de 1 significa que ela vale **uma palavra**, assim a nossa probabilidade com pesos (<code>weighedprob</code> l\u00e1 em cima) ser\u00e1 uma m\u00e9dia ponderada entre a palavra (<code>get</code>) e a probabilidade assumida).\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "NA\u00cfVE BAYES"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Uma vez que temo as probabilidades de cada categoria conter uma certa palavra, podemos combinar as probabilidades de palavras individuais para ter a probabilidade de um documento pertencer a uma dada classe.\n",
      "\n",
      "Este m\u00e9todo se chama 'na\u00efve' (ing\u00eanuo) pois parte da premissa que as probabilidades sendo combinadas s\u00e3o **independentes** (por isso multiplicamos) \u2013 isto \u00e9 \u2013 assumimos que a probabilidade de uma palavra de um documento ocorrer em uma categoria \u00e9 **independente** de todas as outras palavras serem ou n\u00e3o daquela categoria\n",
      "\n",
      "Isto n\u00e3o \u00e9 verdade, N\u00e9?\n",
      "\n",
      "A palavra 'cassino' deve ocorrer junto com 'ganhar' muito mais que com 'alum\u00ednio' ou 'feijoada' (pelo menos eu espero).\n",
      "\n",
      "Para um classificador Naive Bayes, precisamos da probabilidade de um documento inteiro ser dado uma classifica\u00e7\u00e3o. Por assumir independ\u00eancia, podemos somente multiplicar as probabilidades individuais das palavras para obter a do documento. Veja <code>docprob</code> abaixo.\n",
      "\n",
      "\n",
      "Agora sabemos calcular $Pr(Documento | Classe)$, mas isso n\u00e3o serve de muito.\n",
      "\n",
      "Para classificar documentos precisamos de $Pr(Classe | Documento)$, ou seja, dado o documento qual a probabilidade de ele pertencer a uma classe espec\u00edfica."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Teorema de Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Entra o Teorema de Bayes:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$Pr(A|B) = \\frac{Pr(B|A)Pr(A)}{Pr(B)}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ou seja: $$Pr(Classe | Documento) = \\frac{Pr(Documento | Classe) \\cdot Pr(Classe)}{Pr(Documento)}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assim, $Pr(Classe)$ \u00e9 a probabilidade que um documento aleat\u00f3rio ser\u00e1 desta classe, ent\u00e3o \u00e9 s\u00f3 o n\u00famero de documentos na classe divido pelo n\u00famero total de documentos.\n",
      "\n",
      "$Pr(Documento)$ \u00e9 desnecess\u00e1rio pois os resultados n\u00e3o ser\u00e3o usados em uma probabilidade, e sim apenas comparativamente entre classes (e todas ter\u00e3o o mesmo denominador), ent\u00e3o podemos ignor\u00e1-lo!\n",
      "\n",
      "O m\u00e9todo <code>prob</code> calcula a probabilidade da categoria e retorna o produto de $Pr(Document|Category)$ e $Pr(Category)$. Vamos adicionar isto \u00e0 classe NaiveBayes:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NaiveBayes(classifier):\n",
      "    \n",
      "    def docprob(self,  item,  cat):\n",
      "        \"\"\"pega a probabilidade multiplicada de cada feature (palavra) do documento\"\"\"\n",
      "        # pegar as feature\n",
      "        features = self.getfeatures(item)\n",
      "        # Mutiplico as probabilidades de cada feature\n",
      "        p = 1\n",
      "        for f in features:\n",
      "            p *= self.weightedprob(f,   cat,  self.fprob)\n",
      "        return p\n",
      "    \n",
      "    def prob(self, item, cat):\n",
      "        \n",
      "        # calculando Pr(Classe)\n",
      "        catprob = self.catcount(cat) / self.totalcount()\n",
      "        \n",
      "        # calculando Pr(Doc | Classe)\n",
      "        docprob = self.docprob(item, cat)\n",
      "        \n",
      "        # retornando Pr( Classe | Doc) = Pr(Doc | Classe) * Pr(Classe)\n",
      "        return docprob*catprob\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Escolhendo uma categoria"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O ultimo passo \u00e9 escolher uma classe para o documento. A forma mais simples seria calcular as probabilidades de cada classe e escolher a maior.\n",
      "\n",
      "Se estivermos apenas tentando descobrir a classe mais apropriada para um item esta \u00e9 uma estrat\u00e9gia que se aplica, mas em muitas aplica\u00e7\u00f5es \u00e9 melhor o classificador admitir que **n\u00e3o sabe** a resposta do que decidir que a resposta \u00e9 uma categoria com uma probabilidade marginalmente maior.\n",
      "\n",
      "No nosso exemplo de SPAM, \u00e9 muito mais importante **<u>evitar que um email bom seja classificado como spam</u>** do que pegar absolutamente todos os spams. Uma mensagem de spam na _inbox_ de vez em quando pode ser tolerada, mas um email importante que \u00e9 jogado na caixa de spam pode ser negligenciado completamente. Se voc\u00ea precisa olhar no seu folder de spam procurando e-mails importantes, n\u00e3o h\u00e1 raz\u00e3o para _ter_ um folder de spam. \n",
      "\n",
      "Para lidar com isso, podemos colocar um _threshold_, isto \u00e9, um valor m\u00ednimo para cada categoria. Para que um novo documento caia em uma categoria, ela precisa ser >x< mais prov\u00e1vel que qualquer outra, digamos 3. \n",
      "\n",
      "Assim, qualquer mensagem cuja probabilidade \u00e9 alta ..mas n\u00e3o 3 vezes mais alta de ser spam \u00e9 classificada como 'unknown'\n",
      "\n",
      "vamos ver no c\u00f3digo..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "\n",
      "    cl = classifier(getwords)\n",
      "    sampletrain(cl)\n",
      "    print 'fprob for \"money\" being good', cl.fprob('money', 'good')\n",
      "    print 'fprob for \"money\" being bad', cl.fprob('money', 'bad')\n",
      "\n",
      "    print '\\nweightedprob for \"money\" being good', cl.weightedprob('money', 'good', cl.fprob)\n",
      "    print 'weightedprob for \"money\" being bad', cl.weightedprob('money', 'bad', cl.fprob)\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fprob for \"money\" being good 0.0\n",
        "fprob for \"money\" being bad 0.5\n",
        "\n",
        "weightedprob for \"money\" being good 0.25\n",
        "weightedprob for \"money\" being bad 0.5\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    s = \"money, that's what I want\"\n",
      "    print '\\nretraining on new text:\\t\\t','\"'+s+'\"\\n'\n",
      "    cl.train(s, \"bad\")\n",
      "\n",
      "    print 'weightedprob for \"money\" being good', cl.weightedprob('money', 'good', cl.fprob)\n",
      "    print 'weightedprob for \"money\" being bad', cl.weightedprob('money', 'bad', cl.fprob)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "retraining on new text:\t\t\"money, that's what I want\"\n",
        "\n",
        "weightedprob for \"money\" being good 0.166666666667\n",
        "weightedprob for \"money\" being bad 0.611111111111\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    nbClassifier = NaiveBayes(getwords)\n",
      "    sampletrain(nbClassifier)\n",
      "    \n",
      "    print \"\\nis 'quick' good?\", nbClassifier.prob('quick', 'good')\n",
      "    print \"is 'quick'  bad?\",nbClassifier.prob('quick', 'bad')\n",
      "    print \"it is classified as:\",nbClassifier.classify('quick', default='unknown')\n",
      "    \n",
      "    s2 = \"Kobe Bryant is like a quick rabbit with the basketball\"\n",
      "    s3 = \"My daughter wants a quick rabbit for her birthday\"\n",
      "    print '\\nretrainting on two new texts...'\n",
      "    print '\\t\\t\"'+s2+'\"'\n",
      "    print '\\t\\t\"'+s3+'\"' \n",
      "    nbClassifier.train(s2, \"bad\")\n",
      "    nbClassifier.train(s3, \"bad\")\n",
      "    \n",
      "    print \"\\nis 'quick' good?\", nbClassifier.prob('quick', 'good')\n",
      "    print \"is 'quick' bad?\",nbClassifier.prob('quick', 'bad')\n",
      "    print 'now it is:',nbClassifier.classify('quick', default='unknown')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "is 'quick' good? 0.375\n",
        "is 'quick'  bad? 0.2\n",
        "it is classified as: good\n",
        "\n",
        "retrainting on two new texts...\n",
        "\t\t\"Kobe Bryant is like a quick rabbit with the basketball\"\n",
        "\t\t\"My daughter wants a quick rabbit for her birthday\"\n",
        "\n",
        "is 'quick' good? 0.27380952381\n",
        "is 'quick' bad? 0.404761904762\n",
        "now it is: bad\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Naive Bayes: part II</h1>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"Given two sets of readings (in float), $$A$$ and $$B$$, "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}