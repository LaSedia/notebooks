{
 "metadata": {
  "name": "",
  "signature": "sha256:360b8de860fa5cc93b138245afe625c23131606845be7da7509fba8242e1fd8a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# naive bayes\n",
      "# coding: utf-8\n",
      "\n",
      "import re\n",
      "# import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class classifier:\n",
      "    \"\"\" a generic classifier, for use as an example to set up naive bayes \"\"\"\n",
      "    def __init__(self,  getfeatures,  filename=None):\n",
      "        # Counts of feature/category combinations\n",
      "        self.fc = {}\n",
      "        # Counts of documents in each category\n",
      "        self.cc = {}\n",
      "        # function that extract features from each datum\n",
      "        self.getfeatures = getfeatures\n",
      "\n",
      "        self.thresholds = {}\n",
      "\n",
      "    def train(self, item, cat):\n",
      "        features = self.getfeatures(item)\n",
      "        # Increment the count for every feature with this category\n",
      "        for f in features:\n",
      "            self.incf(f, cat)\n",
      "        # Increment the count for this category\n",
      "        self.incc(cat)\n",
      "\n",
      "    def setthreshold(self, cat, t):\n",
      "        self.thresholds[cat] = t\n",
      "    \n",
      "    def getthreshold(self, cat):\n",
      "        if cat not in self.thresholds: return 1.0\n",
      "        return self.thresholds[cat]\n",
      "\n",
      "    # Increase the count of a feature/category pair\n",
      "    def incf(self,  f,  cat):\n",
      "        self.fc.setdefault(f, {})\n",
      "        self.fc[f].setdefault(cat, 0)\n",
      "        self.fc[f][cat] += 1\n",
      "\n",
      "    # Increase the count of a category\n",
      "    def incc(self,  cat):\n",
      "        self.cc.setdefault(cat, 0)\n",
      "        self.cc[cat] += 1\n",
      "\n",
      "    # The number of times a feature has appeared in a category\n",
      "    def fcount(self,  f,  cat):\n",
      "        if f in self.fc and cat in self.fc[f]:\n",
      "            return float(self.fc[f][cat])\n",
      "        return 0.0\n",
      "\n",
      "    # The number of items in a category\n",
      "    def catcount(self,  cat):\n",
      "        if cat in self.cc:\n",
      "            return float(self.cc[cat])\n",
      "        return 0\n",
      "\n",
      "    # The total number of items\n",
      "    def totalcount(self):\n",
      "        return sum(self.cc.values())\n",
      "    \n",
      "    # The list of all categories\n",
      "    def categories(self):\n",
      "        return self.cc.keys()\n",
      "    \n",
      "    def fprob(self, f, cat):\n",
      "        \"\"\"\n",
      "        probability of feature *f* occurring in category *cat*:\n",
      "        The total number of times this feature appeared in this category\n",
      "        divided by the total number of items in this category\n",
      "        \"\"\"\n",
      "        if self.catcount(cat) == 0: return 0  # if the category is empty,  return 0\n",
      "        return self.fcount(f, cat)/self.catcount(cat)\n",
      "    \n",
      "    def weightedprob(self, f, cat, prf, weight=1.0, ap=0.5):\n",
      "        # Calculate current probability\n",
      "        basicprob = prf(f, cat)\n",
      "\n",
      "        # Count the number of times this feature has appeared in # all categories\n",
      "        totals = sum([self.fcount(f, c) for c in self.categories()])\n",
      "        \n",
      "        # Calculate the weighted average\n",
      "        bp = ((weight * ap) + (totals * basicprob)) / (weight + totals)\n",
      "        return bp\n",
      "    \n",
      "    def classify(self, item, default=None):\n",
      "        probs = {}\n",
      "        # Find the category with the highest probability\n",
      "        max = 0.0\n",
      "        for cat in self.categories():\n",
      "            probs[cat] = self.prob(item, cat)\n",
      "            if probs[cat] > max:\n",
      "                max = probs[cat]\n",
      "                best = cat\n",
      "        # Make sure the probability exceeds threshold*next best\n",
      "        for cat in probs:\n",
      "            if cat == best: continue\n",
      "            if probs[cat] * self.getthreshold(best) > probs[best]: return default\n",
      "        return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sampletrain(cl):\n",
      "    cl.train('Nobody owns the water.', 'good')\n",
      "    cl.train('the quick rabbit jumps fences', 'good')\n",
      "    cl.train('buy pharmaceuticals now', 'bad')\n",
      "    cl.train('make quick money at the online casino', 'bad')\n",
      "    cl.train('the quick brown fox jumps', 'good')\n",
      "    cl.train('Mike stores his money in bonds','good')\n",
      "\n",
      "def getwords(doc):\n",
      "    splitter = re.compile('\\\\W*')\n",
      "    # Split the words by non-alpha characters\n",
      "    words = [s.lower() for s in splitter.split(doc) if len(s) > 2 and len(s) < 20]\n",
      "    # Return the unique set of words only\n",
      "    return dict([(w, 1) for w in words])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class naivebayes(classifier):\n",
      "    def docprob(self,  item,  cat):\n",
      "        features = self.getfeatures(item)\n",
      "        # Multiply the probabilities of all the features together\n",
      "        p = 1\n",
      "        for f in features:\n",
      "            p *= self.weightedprob(f,   cat,  self.fprob)\n",
      "        return p\n",
      "    \n",
      "    def prob(self, item, cat):\n",
      "        catprob = self.catcount(cat) / self.totalcount()\n",
      "        docprob = self.docprob(item, cat)\n",
      "        return docprob*catprob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "\n",
      "    cl = classifier(getwords)\n",
      "    sampletrain(cl)\n",
      "    print 'fprob for \"money\" being good', cl.fprob('money', 'good')\n",
      "    print 'fprob for \"money\" being bad', cl.fprob('money', 'bad')\n",
      "\n",
      "    print '\\nweightedprob for \"money\" being good', cl.weightedprob('money', 'good', cl.fprob)\n",
      "    print 'weightedprob for \"money\" being bad', cl.weightedprob('money', 'bad', cl.fprob)\n",
      "    \n",
      "    print '\\nretraining on new text...'\n",
      "    cl.train(\"money, that's what I want\", \"bad\")\n",
      "    \n",
      "    print 'weightedprob for \"money\" being good', cl.weightedprob('money', 'good', cl.fprob)\n",
      "    print 'weightedprob for \"money\" being bad', cl.weightedprob('money', 'bad', cl.fprob)\n",
      "\n",
      "    nbClassifier = naivebayes(getwords)\n",
      "    sampletrain(nbClassifier)\n",
      "    \n",
      "    print '\\nis quick rabbit good?', nbClassifier.prob('quick rabbit', 'good')\n",
      "    print 'is quick rabbit bad?',nbClassifier.prob('quick rabbit', 'bad')\n",
      "    print nbClassifier.classify('quick rabbit', default='unknown')\n",
      "    \n",
      "    print '\\nretrainting on two new texts...'\n",
      "    cl.train(\"Kobe Bryant is very quick rabbit with the basketball\", \"bad\")\n",
      "    cl.train(\"My daughter wants a quick rabbit for her birthday\", \"bad\")\n",
      "    \n",
      "    print 'is quick rabbit good?', nbClassifier.prob('quick rabbit', 'good')\n",
      "    print 'is quick rabbit bad?',nbClassifier.prob('quick rabbit', 'bad')\n",
      "    print nbClassifier.classify('quick rabbit', default='unknown')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fprob for \"money\" being good 0.0\n",
        "fprob for \"money\" being bad 0.5\n",
        "\n",
        "weightedprob for \"money\" being good 0.25\n",
        "weightedprob for \"money\" being bad 0.5\n",
        "\n",
        "retraining on new text...\n",
        "weightedprob for \"money\" being good 0.166666666667\n",
        "weightedprob for \"money\" being bad 0.611111111111\n",
        "\n",
        "is quick rabbit good? 0.15625\n",
        "is quick rabbit bad? 0.05\n",
        "good\n",
        "\n",
        "retrainting on two new texts...\n",
        "is quick rabbit good? 0.15625\n",
        "is quick rabbit bad? 0.05\n",
        "good\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}